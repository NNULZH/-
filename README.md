# 似然函数中的“似然”是什么

## 一、比喻：神秘的袋子与红球、蓝球

假设你有一个神秘的袋子，里面装着红球和蓝球。你不知道袋子里红球和蓝球的比例（这是我们要“估计”的参数），但你可以从袋子里摸球来看。

- 你摸了 10 次，拿到了 7 个红球、3 个蓝球。  
- 现在你想反推：袋子里红球的比例大概是多少？

## 二、什么是“似然”？

- **似然**：在已知观测结果（7 红 3 蓝）的情况下，判断某个参数假设（比如红球比例为 70% 或 20%）有多“合理”。  
  - 如果假设红球比例是 70%，那观察到“7 红 3 蓝”这组结果，就很“自然”、很“合理”。  
  - 如果假设红球比例是 20%，那同样的结果就很“不自然”、不太可能出现。

### 似然 vs. 概率

|   | 知道的 | 要求的                      |
|---|--------|-----------------------------|
| 概率（Probability） | 参数   | 数据发生的概率（已知参数，算结果） |
| 似然（Likelihood）   | 数据   | 参数“有多合理”（已知结果，评估参数） |

## 三、构造似然函数

令参数 \(\theta\) = 袋子中红球的比例，观测到 \(k\) 次红球、\(n-k\) 次蓝球：

$$\[
L(\theta) \;=\; P(\text{观测到 }k\text{ 红},\,n-k\text{ 蓝}\mid \theta)
\;=\;\theta^k \,(1-\theta)^{\,n-k}
\]$$

我们就可以在不同 \(\theta\) 值上比较，找出“使观测结果最合理”的那个 \(\theta\)。

---

# 最大似然法推导逻辑回归

## 一、问题设置

- 目标：给定输入特征向量 \(x\)，预测二分类标签 \(y\in\{0,1\}\)。  
- 训练集：\(\{(x^{(i)},y^{(i)})\}_{i=1}^m\)。

## 二、模型假设

- 定义模型输出：  
  $$\[
  h_\theta(x) \;=\; P(y=1\mid x;\theta)
  \;=\;\sigma(\theta^T x)
  \;=\;\frac{1}{1+e^{-\theta^T x}}
  \]$$
- 如果 \(y=1\)，它的预测概率就是 \(h_\theta(x)\)；如果 \(y=0\)，预测概率就是 \(1 - h_\theta(x)\)。

## 三、写出似然函数

单个样本 \((x^{(i)},y^{(i)})\) 的似然：

$$\[
P\bigl(y^{(i)}\mid x^{(i)};\theta\bigr)
=\bigl[h_\theta(x^{(i)})\bigr]^{y^{(i)}}
\bigl[1 - h_\theta(x^{(i)})\bigr]^{1 - y^{(i)}}
\]$$

全数据集的似然函数：

$$\[
L(\theta)
=\prod_{i=1}^m
\bigl[h_\theta(x^{(i)})\bigr]^{y^{(i)}}
\bigl[1 - h_\theta(x^{(i)})\bigr]^{1 - y^{(i)}}
\]$$

## 四、对数似然（Log-Likelihood）

取对数简化乘积：

$$\[
\ell(\theta)
= \log L(\theta)
= \sum_{i=1}^m \Bigl[
    y^{(i)}\log h_\theta(x^{(i)})
  + (1 - y^{(i)})\log\bigl(1 - h_\theta(x^{(i)})\bigr)
  \Bigr]
\]$$

## 五、最大化对数似然

- 目标：$$\(\displaystyle \hat\theta = \arg\max_\theta \,\ell(\theta)\)。  
- 通常使用梯度下降或其他数值优化方法来求解最优 \(\theta\)。

---

> **核心要点：**  
> 1. 逻辑回归是一个**概率模型**，通过最大化“在此模型下观测到训练标签的似然”来求参数。  
> 2. 似然函数 \(L(\theta)\) 是已知数据，衡量不同参数 \(\theta\) 下数据“出现得有多合理”。  
> 3. 对数似然 \(\ell(\theta)\) 将乘积变求和，更易于求导和优化。  
